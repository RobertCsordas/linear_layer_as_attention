{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "MNIST FF attention",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "console": "integratedTerminal",
            "args": ["--name", "mnist_ff_attention", "--task", "mnist_ff_attention", "--log", "tb",
                     "--keep_alive", "1", "-reset", "1", "-stop_after", "1000",
                     "-save_interval", "10000000000", "-lr", "3e-3", "-dropout", "0.0", 
                    "-wd", "0", "-optimizer", "sgd", "-batch_size", "128",
                    "-test_interval", "1000", "-layer_sizes", "800,800", "-ff_as_attention.analyze_n_samples", "4"]
        },

        {
            "name": "MNIST FMNIST FF attention",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "console": "integratedTerminal",
            "args": ["--name", "mnist__fmnist_ff_attention", "--task", "mnist_fmnist_ff_attention", "--log", "tb",
                     "--keep_alive", "1", "-reset", "1", "-stop_after", "200",
                     "-save_interval", "10000000000", "-lr", "3e-3", "-dropout", "0.0", 
                    "-wd", "0", "-optimizer", "sgd", "-batch_size", "128",
                    "-test_interval", "1000", "-layer_sizes", "800,800"],
        },

        {
            "name": "MNIST FMNIST FF attention sequential",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "console": "integratedTerminal",
            "args": ["--name", "mnist__fmnist_ff_attention_sequential", "--task", "mnist_fmnist_sequential_ff_attention", "--log", "tb",
                     "--keep_alive", "1", "-reset", "1", "-stop_after", "100",
                     "-save_interval", "10000000000", "-lr", "3e-3", "-dropout", "0.0", 
                    "-wd", "0", "-optimizer", "sgd", "-batch_size", "128",
                    "-test_interval", "1000", "-layer_sizes", "800,800", "-mnist_fmnist_seq.switch_timesteps", "50"]
        },

   
        {
            "name": "Language LSTM FF attemntion",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "console": "integratedTerminal",
            "args": ["--name", "lstm_lang_ff_att", "--profile", "enwik8_lstm", "--log", "tb",
                     "--keep_alive", "1", "-reset", "1", "-state_size", "200", "-amp", "1", "-stop_after", "10",
                     "--embedding_size", "none", "-n_layers", "1", "-test_interval", "1000", "-dropout", "0.5", "-batch_size", "128",
                     "--optimizer", "adam", "-lr", "1e-3",
                     "--save_interval", "100000000",
                     "--tied_embedding", "0", "--task", "language_lstm_ff_attention", "-ff_as_attention.hugepath", "/data/tmp"]
        },

       
        {
            "name": "Wikitext 2 overfit",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "console": "integratedTerminal",
            "args": ["--name", "wikitext_2_lstm_overfit", "--log", "tb",
                     "--keep_alive", "1", "-reset", "1", "-state_size", "1024", "-amp", "1", "-stop_after", "1000",
                     "-n_layers", "1", "-test_interval", "2000", "-dropout", "0.0", "-batch_size", "64",
                     "--optimizer", "adam", "-adam.betas", "0.99,0.999", "-adam.eps","1e-9", "-lr", "0.001", "-n_layers", "1", "-grad_clip", "0.1",
                     "--save_interval", "100000000",  "-embedding_size", "1024",
                     "--tied_embedding", "0", "--task", "language_lstm_ff_attention"]
        },

        {
            "name": "LM analysis overfit",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "console": "integratedTerminal",
            "args": ["--name", "lm_analysis_overfit", "--log", "tb",
                     "--keep_alive", "1", "-reset", "1", "-state_size", "1024", "-amp", "1", "-stop_after", "100",
                     "-n_layers", "1", "-test_interval", "2000", "-dropout", "0.0", "-batch_size", "64",
                     "--optimizer", "adam", "-lr", "0.001", "-n_layers", "1", "-grad_clip", "1.0",
                     "--save_interval", "100000000",  "-embedding_size", "64",
                     "--tied_embedding", "0", "--task", "language_lstm_ff_attention_overfit", "-ff_as_attention.hugepath", "/data/tmp"]
        },

        {
            "name": "CIFAR 10 FF attention",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "console": "integratedTerminal",
            "args": ["--name", "cifar10_ff_attention", "--task", "cifar10_ff_attention", "--log", "tb",
                     "--keep_alive", "1", "-reset", "1", "-stop_after", "1000",
                     "-save_interval", "10000000000", "-lr", "3e-3", "-dropout", "0.0",
                    "-wd", "0", "-optimizer", "sgd", "-batch_size", "128",
                    "-test_interval", "1000", "-layer_sizes", "800,800"]
        },

        {
            "type": "python",
            "request": "launch",
            "name": "Debug File",
            "justMyCode": false,
            "program": "${file}",
            "cwd": "${fileDirname}"
        }
    ]
}